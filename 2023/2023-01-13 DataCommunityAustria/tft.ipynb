{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1c168f-aaca-4f3d-9b57-97f31a8fcfc8",
   "metadata": {},
   "source": [
    "# The basics\n",
    "\n",
    "This code is based on the example found at https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91\n",
    "\n",
    "First install some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2547c7f8-1e8a-4e7e-93e0-52b7855bd11e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /anaconda/envs/py38_default/lib/python3.8/site-packages (1.13.1)\n",
      "Requirement already satisfied: pytorch-lightning in /anaconda/envs/py38_default/lib/python3.8/site-packages (1.8.6)\n",
      "Requirement already satisfied: pytorch_forecasting in /anaconda/envs/py38_default/lib/python3.8/site-packages (0.10.3)\n",
      "Requirement already satisfied: numpy in /anaconda/envs/py38_default/lib/python3.8/site-packages (1.23.0)\n",
      "Requirement already satisfied: typing_extensions in /anaconda/envs/py38_default/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: tensorboardX>=2.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch-lightning) (2.5.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch-lightning) (4.64.1)\n",
      "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch-lightning) (0.5.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch-lightning) (2022.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch-lightning) (0.11.0)\n",
      "Requirement already satisfied: optuna<3.0.0,>=2.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch_forecasting) (2.10.1)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch_forecasting) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn<1.2,>=0.24 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch_forecasting) (1.1.1)\n",
      "Requirement already satisfied: statsmodels in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch_forecasting) (0.13.5)\n",
      "Requirement already satisfied: matplotlib in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch_forecasting) (3.6.3)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pytorch_forecasting) (1.9.3)\n",
      "Requirement already satisfied: requests in /anaconda/envs/py38_default/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n",
      "Requirement already satisfied: cliff in /anaconda/envs/py38_default/lib/python3.8/site-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.1.0)\n",
      "Requirement already satisfied: colorlog in /anaconda/envs/py38_default/lib/python3.8/site-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (6.7.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.4.45)\n",
      "Requirement already satisfied: alembic in /anaconda/envs/py38_default/lib/python3.8/site-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.9.1)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2022.7)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.24->pytorch_forecasting) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.24->pytorch_forecasting) (2.2.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboardX>=2.2->pytorch-lightning) (3.19.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from matplotlib->pytorch_forecasting) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from matplotlib->pytorch_forecasting) (1.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from matplotlib->pytorch_forecasting) (9.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from matplotlib->pytorch_forecasting) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from matplotlib->pytorch_forecasting) (4.38.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from statsmodels->pytorch_forecasting) (0.5.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: six in /anaconda/envs/py38_default/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels->pytorch_forecasting) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.0.1)\n",
      "Requirement already satisfied: importlib-resources in /anaconda/envs/py38_default/lib/python3.8/site-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (5.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /anaconda/envs/py38_default/lib/python3.8/site-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.11.3)\n",
      "Requirement already satisfied: Mako in /anaconda/envs/py38_default/lib/python3.8/site-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.2.4)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.5.1)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (3.6.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.1.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.13)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from importlib-metadata->alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (3.8.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from stevedore>=2.0.1->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (5.11.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from Mako->alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch pytorch-lightning pytorch_forecasting numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1e824d",
   "metadata": {},
   "source": [
    "import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer\n",
    "from pytorch_forecasting.models.baseline import Baseline\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics.quantile import QuantileLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3dde68-bcb6-4117-a419-37b3de866354",
   "metadata": {},
   "source": [
    "Steps to execute:\n",
    "1. Create a pandas dataframe with our time-series data.\n",
    "2. Wrap our dataframe into a TimeSeriesDataset instance.\n",
    "3. Pass our TimeSeriesDataset instance to TemporalFusionTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e96178-569a-4fdc-b6b6-3bb3230da9f1",
   "metadata": {},
   "source": [
    "Minimal dataset\n",
    "First create a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146a372-35c0-4fed-b63f-4f47b40642b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.DataFrame(\n",
    "    dict(\n",
    "        time_idx=np.tile(np.arange(6), 3),\n",
    "        target=np.array([0,1,2,3,4,5,20,21,22,23,24,25,40,41,42,43,44,45]),\n",
    "        group=np.repeat(np.arange(3), 6),\n",
    "        holidays = np.tile(['X','Black Friday', 'X','Christmas','X', 'X'],3),\n",
    "    )\n",
    ")\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6482c5-36f9-487f-8222-d79bdd4f84fb",
   "metadata": {},
   "source": [
    "Then convert the dataframe into a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b02e4-4de0-40a9-ace9-b4d669878c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TimeSeriesDataSet(\n",
    "    sample_data,\n",
    "    group_ids=[\"group\"],\n",
    "    target=\"target\",\n",
    "    time_idx=\"time_idx\",\n",
    "    max_encoder_length=2,\n",
    "    max_prediction_length=3,\n",
    "    time_varying_unknown_reals=[\"target\"],\n",
    "    static_categoricals=[\"holidays\"],\n",
    "    target_normalizer=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419c263-6785-460d-bb03-74d293471cec",
   "metadata": {},
   "source": [
    "This is how the dataset will be passed to the TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba471c-eedd-4a39-a6f8-13765b493a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the dataset to a dataloader\n",
    "dataloader = dataset.to_dataloader(batch_size=1)\n",
    "\n",
    "#load the first batch\n",
    "x, y = next(iter(dataloader))\n",
    "print(x['encoder_target'])\n",
    "print(x['groups'])\n",
    "print('\\n')\n",
    "print(x['decoder_target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3826715d-d983-4a21-ae54-68b9df540952",
   "metadata": {},
   "source": [
    "# See it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ffdb29-ecc6-46a5-8a5e-f16bec407915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-13 08:07:12--  https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 261335609 (249M) [application/x-httpd-php]\n",
      "Saving to: ‘LD2011_2014.txt.zip’\n",
      "\n",
      "LD2011_2014.txt.zip 100%[===================>] 249.23M  17.7MB/s    in 15s     \n",
      "\n",
      "2023-01-13 08:07:28 (16.6 MB/s) - ‘LD2011_2014.txt.zip’ saved [261335609/261335609]\n",
      "\n",
      "Archive:  LD2011_2014.txt.zip\n",
      "  inflating: LD2011_2014.txt         \n",
      "   creating: __MACOSX/\n",
      "  inflating: __MACOSX/._LD2011_2014.txt  \n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip\n",
    "!unzip LD2011_2014.txt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6698f0c1-6782-4243-8f25-85c6e77ba8b0",
   "metadata": {},
   "source": [
    "Put the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadbda88-9092-49f6-96f4-61d876aebef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('LD2011_2014.txt', index_col=0, sep=';', decimal=',')\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.sort_index(inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e41d10-f929-483d-8ce2-975f28508eaa",
   "metadata": {},
   "source": [
    "Aggregate data by hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31cfbdc-47ce-4359-b5bd-58dda185b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.resample('1h').mean().replace(0., np.nan)\n",
    "earliest_time = data.index.min()\n",
    "df=data[['MT_002', 'MT_004', 'MT_005', 'MT_006', 'MT_008' ]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263b16f5-04dd-43a3-a021-ccf98c3308b1",
   "metadata": {},
   "source": [
    "Reformat data frame to match expected input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569d5ab-14cd-42a0-bdfb-6ab9d4bb3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for label in df:\n",
    "\n",
    "    ts = df[label]\n",
    "\n",
    "    start_date = min(ts.fillna(method='ffill').dropna().index)\n",
    "    end_date = max(ts.fillna(method='bfill').dropna().index)\n",
    "\n",
    "    active_range = (ts.index >= start_date) & (ts.index <= end_date)\n",
    "    ts = ts[active_range].fillna(0.)\n",
    "\n",
    "    tmp = pd.DataFrame({'power_usage': ts})\n",
    "    date = tmp.index\n",
    "\n",
    "    tmp['hours_from_start'] = (date - earliest_time).seconds / 60 / 60 + (date - earliest_time).days * 24\n",
    "    tmp['hours_from_start'] = tmp['hours_from_start'].astype('int')\n",
    "  \n",
    "    tmp['days_from_start'] = (date - earliest_time).days\n",
    "    tmp['date'] = date\n",
    "    tmp['consumer_id'] = label\n",
    "    tmp['hour'] = date.hour\n",
    "    tmp['day'] = date.day\n",
    "    tmp['day_of_week'] = date.dayofweek\n",
    "    tmp['month'] = date.month\n",
    "\n",
    "    #stack all time series vertically\n",
    "    df_list.append(tmp)\n",
    "\n",
    "time_df = pd.concat(df_list).reset_index(drop=True)\n",
    "\n",
    "# match results in the original paper\n",
    "time_df = time_df[(time_df['days_from_start'] >= 1096)\n",
    "                & (time_df['days_from_start'] < 1346)].copy()\n",
    "\n",
    "time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157da4f-edac-4c87-82ab-2e7bbcb0c9ae",
   "metadata": {},
   "source": [
    "Take a closer look into the data, average consumption by consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813bdc3-11f3-4ceb-8508-b8603bef0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df[['consumer_id','power_usage']].groupby('consumer_id').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e5e3f-8142-4982-8695-93b4920f37e9",
   "metadata": {},
   "source": [
    "Create data loaders for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aca77f-a89a-4670-abf4-0c4c30bd0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 24\n",
    "max_encoder_length = 7*24\n",
    "training_cutoff = time_df[\"hours_from_start\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    time_df[lambda x: x.hours_from_start <= training_cutoff],\n",
    "    time_idx=\"hours_from_start\",\n",
    "    target=\"power_usage\",\n",
    "    group_ids=[\"consumer_id\"],\n",
    "    min_encoder_length=max_encoder_length // 2, \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"consumer_id\"],\n",
    "    time_varying_known_reals=[\"hours_from_start\",\"day\",\"day_of_week\", \"month\", 'hour'],\n",
    "    time_varying_unknown_reals=['power_usage'],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"consumer_id\"], transformation=\"softplus\"\n",
    "    ),  # we normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, time_df, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for  our model\n",
    "batch_size = 64 \n",
    "# if you have a strong GPU, feel free to increase the number of workers  \n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=4)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5933cf-9105-441e-b079-95d5abaf4cf5",
   "metadata": {},
   "source": [
    "Define a baseline prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802b918-ab9b-4159-b284-c4e6a840e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484344d3-2766-4148-93da-5a849f1b726a",
   "metadata": {},
   "source": [
    "Train the TFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8584365-ff37-4eb4-99ce-27b4f40691c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: lightning_logs/lightning_logs\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 20    \n",
      "3  | prescalers                         | ModuleDict                      | 3.2 K \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 313 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 734 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 628 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 103 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 103 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 103 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 103 K \n",
      "11 | lstm_encoder                       | LSTM                            | 206 K \n",
      "12 | lstm_decoder                       | LSTM                            | 206 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 51.5 K\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 320   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 128 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 64.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 51.8 K\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 103 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 51.8 K\n",
      "20 | output_layer                       | Linear                          | 1.1 K \n",
      "----------------------------------------------------------------------------------------\n",
      "3.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 M     Total params\n",
      "11.818    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58732a90ec1d49ce80e5e4edabc65253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 4.789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1.129 >= min_delta = 0.0001. New best score: 3.660\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.222 >= min_delta = 0.0001. New best score: 3.438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0001. New best score: 3.419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 3.419. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=True, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  \n",
    "logger = TensorBoardLogger(\"lightning_logs\")  \n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=45,\n",
    "    # accelerator='gpu', # if supported by your hardware \n",
    "    devices=1,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.001,\n",
    "    hidden_size=160,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=160,\n",
    "    output_size=7,  # there are 7 quantiles by default: [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10, \n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b72fe-0a23-4e2d-83fe-064e844b7946",
   "metadata": {},
   "source": [
    "Get the best model from the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0a3ac-486d-4c44-908b-ac2e9b4771b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(best_model_path)\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6d7af-9c92-483d-8e34-23e59c84a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "\n",
    "#average p50 loss overall\n",
    "print((actuals - predictions).abs().mean().item())\n",
    "#average p50 loss per time series\n",
    "print((actuals - predictions).abs().mean(axis=1))\n",
    "\n",
    "# 6.586348056793213\n",
    "# tensor([ 0.9898,  7.5671,  2.0603,  9.5627, 12.7517])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669bfd05-82c6-412c-96e6-75ea0a225b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at what the raw_predictions variable contains\n",
    "\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "print(raw_predictions._fields)\n",
    "# ('prediction', \n",
    "# 'encoder_attention', \n",
    "# 'decoder_attention', \n",
    "# 'static_variables', \n",
    "# 'encoder_variables', \n",
    "# 'decoder_variables', \n",
    "# 'decoder_lengths', \n",
    "# 'encoder_lengths')\n",
    "\n",
    "print('\\n')\n",
    "print(raw_predictions['prediction'].shape)\n",
    "#torch.Size([5, 24, 7])\n",
    "\n",
    "# We get predictions of 5 time-series for 24 days.\n",
    "# For each day we get 7 predictions - these are the 7 quantiles:\n",
    "#[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]\n",
    "# We are mostly interested in the 4th quantile which represents, let's say, the 'median loss'\n",
    "# fyi, although docs use the term quantiles, the most accurate term are percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de88a4e-f542-4208-b1bc-e7599eb1b356",
   "metadata": {},
   "source": [
    "We can now also look at sample predictions directly which we plot with plot_prediction(). As you can see from the figures below, forecasts look rather accurate. If you wonder, the grey lines denote the amount of attention the model pays to different points in time when making the prediction. This is a special feature of the Temporal Fusion Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a186db-0a72-4256-9b60-a87a27ea9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx in range(5):  # plot all 5 consumers\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1f737-1df9-4a24-a088-e162d47a91d8",
   "metadata": {},
   "source": [
    "Actuals vs predictions by variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb4227-3011-4645-9d0b-2b951e7b5129",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, x = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(x, predictions)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090ea9d-fc97-4b4d-bc3b-49c358c7f6ee",
   "metadata": {},
   "source": [
    "Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05c7d2-f276-467c-9248-7fd420ad8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "interpretation = best_tft.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5eaef-d2a5-46bc-80a4-9ee4a39416d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_default",
   "language": "python",
   "name": "conda-env-py38_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
