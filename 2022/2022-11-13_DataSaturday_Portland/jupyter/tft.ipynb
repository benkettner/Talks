{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1c168f-aaca-4f3d-9b57-97f31a8fcfc8",
   "metadata": {},
   "source": [
    "# The basics\n",
    "\n",
    "This code is based on the example found at https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91\n",
    "\n",
    "First install some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2547c7f8-1e8a-4e7e-93e0-52b7855bd11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Python310\\\\Lib\\\\site-packages\\\\tensorboard_plugin_wit\\\\static\\\\wit_tb_bin.js'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp310-cp310-win_amd64.whl (167.3 MB)\n",
      "     ------------------------------------ 167.3/167.3 MB 628.1 kB/s eta 0:00:00\n",
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-1.8.1-py3-none-any.whl (798 kB)\n",
      "Collecting pytorch_forecasting\n",
      "  Using cached pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting PyYAML>=5.4\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Using cached torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
      "Collecting lightning-utilities==0.3.*\n",
      "  Using cached lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Using cached fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\python310\\lib\\site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting fire\n",
      "  Using cached fire-0.4.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting optuna<3.0.0,>=2.3.0\n",
      "  Using cached optuna-2.10.1-py3-none-any.whl (308 kB)\n",
      "Collecting pandas<2.0.0,>=1.3.0\n",
      "  Downloading pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "     -------------------------------------- 10.4/10.4 MB 732.5 kB/s eta 0:00:00\n",
      "Collecting statsmodels\n",
      "  Using cached statsmodels-0.13.5-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.6.2-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "Collecting scipy<2.0,>=1.8\n",
      "  Using cached scipy-1.9.3-cp310-cp310-win_amd64.whl (40.1 MB)\n",
      "Collecting scikit-learn<1.2,>=0.24\n",
      "  Using cached scikit_learn-1.1.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.8.3-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Using cached cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Collecting cliff\n",
      "  Using cached cliff-4.0.0-py3-none-any.whl (80 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Using cached SQLAlchemy-1.4.43-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting protobuf<4,>=3.9.2\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.50.0-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python310\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (58.1.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.4)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.6-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.1-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp310-cp310-win_amd64.whl (27 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "     -------------------------------------- 140.4/140.4 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.1-cp310-cp310-win_amd64.whl (190 kB)\n",
      "     -------------------------------------- 190.9/190.9 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning) (2.1.1)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.3-py3-none-any.whl (78 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Using cached stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Using cached prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Using cached cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "Collecting termcolor\n",
      "  Using cached termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\python310\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.5)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting pyperclip>=1.6\n",
      "  Using cached pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "     -------------------------------------- 112.6/112.6 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, pytz, pyreadline3, pyperclip, pyasn1, zipp, wheel, werkzeug, urllib3, typing-extensions, tqdm, threadpoolctl, termcolor, tensorboard-data-server, rsa, PyYAML, pyasn1-modules, protobuf, PrettyTable, pillow, pbr, oauthlib, numpy, multidict, markdown, Mako, kiwisolver, joblib, grpcio, greenlet, fsspec, frozenlist, fonttools, cycler, colorlog, cmd2, charset-normalizer, certifi, cachetools, autopage, async-timeout, absl-py, yarl, torch, stevedore, sqlalchemy, scipy, requests, patsy, pandas, importlib-metadata, google-auth, fire, contourpy, cmaes, aiosignal, torchmetrics, statsmodels, scikit-learn, requests-oauthlib, matplotlib, lightning-utilities, cliff, alembic, aiohttp, optuna, google-auth-oauthlib, tensorboard, pytorch-lightning, pytorch_forecasting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Python310\\\\Lib\\\\site-packages\\\\pyreadline3\\\\lineeditor\\\\history.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp310-cp310-win_amd64.whl (167.3 MB)\n",
      "     ------------------------------------ 167.3/167.3 MB 469.8 kB/s eta 0:00:00\n",
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-1.8.1-py3-none-any.whl (798 kB)\n",
      "Collecting pytorch_forecasting\n",
      "  Using cached pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Using cached torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Using cached fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\python310\\lib\\site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting lightning-utilities==0.3.*\n",
      "  Using cached lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting PyYAML>=5.4\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting fire\n",
      "  Using cached fire-0.4.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.6.2-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 771.3 kB/s eta 0:00:00\n",
      "Collecting optuna<3.0.0,>=2.3.0\n",
      "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
      "     ------------------------------------ 308.2/308.2 kB 464.9 kB/s eta 0:00:00\n",
      "Collecting scipy<2.0,>=1.8\n",
      "  Using cached scipy-1.9.3-cp310-cp310-win_amd64.whl (40.1 MB)\n",
      "Collecting pandas<2.0.0,>=1.3.0\n",
      "  Downloading pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "     ---------------------------------------- 10.4/10.4 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.13.5-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "     ---------------------------------------- 9.1/9.1 MB 977.4 kB/s eta 0:00:00\n",
      "Collecting scikit-learn<1.2,>=0.24\n",
      "  Using cached scikit_learn-1.1.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.8.3-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Using cached cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Collecting cliff\n",
      "  Using cached cliff-4.0.0-py3-none-any.whl (80 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Using cached SQLAlchemy-1.4.43-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.50.0-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python310\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (58.1.0)\n",
      "Collecting protobuf<4,>=3.9.2\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.4)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 55.3/55.3 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.6-cp310-cp310-win_amd64.whl (163 kB)\n",
      "     -------------------------------------- 163.6/163.6 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "     -------------------------------------- 233.8/233.8 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp310-cp310-win_amd64.whl (55 kB)\n",
      "     -------------------------------------- 55.9/55.9 kB 972.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp310-cp310-win_amd64.whl (27 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "     -------------------------------------- 161.1/161.1 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "     -------------------------------------- 140.4/140.4 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.1-cp310-cp310-win_amd64.whl (190 kB)\n",
      "     -------------------------------------- 190.9/190.9 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning) (2.1.1)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.7/78.7 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "     -------------------------------------- 147.1/147.1 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Using cached prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Using cached stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Using cached autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\python310\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "     -------------------------------------- 112.6/112.6 kB 6.4 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, pytz, pyreadline3, pyperclip, pyasn1, zipp, wheel, werkzeug, urllib3, typing-extensions, tqdm, threadpoolctl, termcolor, tensorboard-data-server, rsa, PyYAML, pyasn1-modules, protobuf, PrettyTable, pillow, pbr, oauthlib, numpy, multidict, markdown, Mako, kiwisolver, joblib, grpcio, greenlet, fsspec, frozenlist, fonttools, cycler, colorlog, cmd2, charset-normalizer, certifi, cachetools, autopage, async-timeout, absl-py, yarl, torch, stevedore, sqlalchemy, scipy, requests, patsy, pandas, importlib-metadata, google-auth, fire, contourpy, cmaes, aiosignal, torchmetrics, statsmodels, scikit-learn, requests-oauthlib, matplotlib, lightning-utilities, cliff, alembic, aiohttp, optuna, google-auth-oauthlib, tensorboard, pytorch-lightning, pytorch_forecasting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp310-cp310-win_amd64.whl (167.3 MB)\n",
      "     ------------------------------------ 167.3/167.3 MB 415.5 kB/s eta 0:00:00\n",
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-1.8.1-py3-none-any.whl (798 kB)\n",
      "Collecting pytorch_forecasting\n",
      "  Using cached pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting lightning-utilities==0.3.*\n",
      "  Using cached lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Using cached torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\python310\\lib\\site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Using cached fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "Collecting PyYAML>=5.4\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting fire\n",
      "  Using cached fire-0.4.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn<1.2,>=0.24\n",
      "  Using cached scikit_learn-1.1.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.13.5-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "     ---------------------------------------- 9.1/9.1 MB 936.7 kB/s eta 0:00:00\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.6.2-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "Collecting optuna<3.0.0,>=2.3.0\n",
      "  Using cached optuna-2.10.1-py3-none-any.whl (308 kB)\n",
      "Collecting pandas<2.0.0,>=1.3.0\n",
      "  Using cached pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "Collecting scipy<2.0,>=1.8\n",
      "  Using cached scipy-1.9.3-cp310-cp310-win_amd64.whl (40.1 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.8.3-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Using cached SQLAlchemy-1.4.43-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Using cached cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "Collecting cliff\n",
      "  Using cached cliff-4.0.0-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.50.0-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting protobuf<4,>=3.9.2\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python310\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (58.1.0)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.4)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.6-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.1-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp310-cp310-win_amd64.whl (27 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-2.0.1-cp310-cp310-win_amd64.whl (190 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning) (2.1.1)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.3-py3-none-any.whl (78 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Using cached stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Using cached autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Using cached prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Using cached cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "Collecting termcolor\n",
      "  Using cached termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\python310\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.5)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Using cached pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Using cached pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pytz, pyreadline3, pyperclip, pyasn1, zipp, wheel, werkzeug, urllib3, typing-extensions, tqdm, threadpoolctl, termcolor, tensorboard-data-server, rsa, PyYAML, pyasn1-modules, protobuf, PrettyTable, pillow, pbr, oauthlib, numpy, multidict, markdown, Mako, kiwisolver, joblib, grpcio, greenlet, fsspec, frozenlist, fonttools, cycler, colorlog, cmd2, charset-normalizer, certifi, cachetools, autopage, async-timeout, absl-py, yarl, torch, stevedore, sqlalchemy, scipy, requests, patsy, pandas, importlib-metadata, google-auth, fire, contourpy, cmaes, aiosignal, torchmetrics, statsmodels, scikit-learn, requests-oauthlib, matplotlib, lightning-utilities, cliff, alembic, aiohttp, optuna, google-auth-oauthlib, tensorboard, pytorch-lightning, pytorch_forecasting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Python310\\\\Lib\\\\site-packages\\\\pyreadline3\\\\test\\\\test_vi.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "  DEPRECATION: pyperclip is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python310\\\\Scripts\\\\wheel.exe' -> 'C:\\\\Python310\\\\Scripts\\\\wheel.exe.deleteme'\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp310-cp310-win_amd64.whl (167.3 MB)\n",
      "     ------------------------------------ 167.3/167.3 MB 577.6 kB/s eta 0:00:00\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.8.1-py3-none-any.whl (798 kB)\n",
      "     ------------------------------------ 798.4/798.4 kB 813.4 kB/s eta 0:00:00\n",
      "Collecting pytorch_forecasting\n",
      "  Downloading pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\n",
      "     ------------------------------------ 141.4/141.4 kB 701.2 kB/s eta 0:00:00\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\python310\\lib\\site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     -------------------------------------- 78.5/78.5 kB 437.4 kB/s eta 0:00:00\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
      "     ------------------------------------ 529.7/529.7 kB 790.6 kB/s eta 0:00:00\n",
      "Collecting numpy>=1.17.2\n",
      "  Downloading numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "     -------------------------------------- 14.6/14.6 MB 980.6 kB/s eta 0:00:00\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "     ---------------------------------------- 6.0/6.0 MB 712.8 kB/s eta 0:00:00\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "     ------------------------------------ 139.5/139.5 kB 828.4 kB/s eta 0:00:00\n",
      "Collecting PyYAML>=5.4\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     ------------------------------------ 151.7/151.7 kB 822.2 kB/s eta 0:00:00\n",
      "Collecting lightning-utilities==0.3.*\n",
      "  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "     -------------------------------------- 87.7/87.7 kB 549.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scipy<2.0,>=1.8\n",
      "  Downloading scipy-1.9.3-cp310-cp310-win_amd64.whl (40.1 MB)\n",
      "     -------------------------------------- 40.1/40.1 MB 864.0 kB/s eta 0:00:00\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.13.5-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "     ---------------------------------------- 9.1/9.1 MB 927.8 kB/s eta 0:00:00\n",
      "Collecting scikit-learn<1.2,>=0.24\n",
      "  Downloading scikit_learn-1.1.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "     ---------------------------------------- 7.5/7.5 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting pandas<2.0.0,>=1.3.0\n",
      "  Downloading pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "     ---------------------------------------- 10.4/10.4 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting optuna<3.0.0,>=2.3.0\n",
      "  Using cached optuna-2.10.1-py3-none-any.whl (308 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.6.2-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "     -------------------------------------- 62.8/62.8 kB 281.3 kB/s eta 0:00:00\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.3-cp310-cp310-win_amd64.whl (319 kB)\n",
      "     -------------------------------------- 319.7/319.7 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting cliff\n",
      "  Downloading cliff-4.0.0-py3-none-any.whl (80 kB)\n",
      "     ---------------------------------------- 81.0/81.0 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.43-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "     -------------------------------------- 209.8/209.8 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "     -------------------------------------- 498.1/498.1 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     -------------------------------------- 298.0/298.0 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "     ------------------------------------ 124.6/124.6 kB 811.0 kB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "     -------------------------------------- 175.4/175.4 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     -------------------------------------- 93.3/93.3 kB 883.6 kB/s eta 0:00:00\n",
      "Collecting protobuf<4,>=3.9.2\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "     ------------------------------------ 904.0/904.0 kB 893.8 kB/s eta 0:00:00\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ------------------------------------ 781.3/781.3 kB 536.6 kB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python310\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (58.1.0)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "     ------------------------------------ 232.7/232.7 kB 710.7 kB/s eta 0:00:00\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.50.0-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 948.4 kB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.4)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "     -------------------------------------- 965.4/965.4 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.6-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "     -------------------------------------- 233.8/233.8 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.1-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp310-cp310-win_amd64.whl (27 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     -------------------------------------- 155.3/155.3 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "     -------------------------------------- 140.4/140.4 kB 8.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.1-cp310-cp310-win_amd64.whl (190 kB)\n",
      "     -------------------------------------- 190.9/190.9 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning) (2.1.1)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.3-py3-none-any.whl (78 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.0/50.0 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Using cached cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\python310\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Using cached pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Using cached pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pytz, pyreadline3, pyperclip, pyasn1, zipp, wheel, werkzeug, urllib3, typing-extensions, tqdm, threadpoolctl, termcolor, tensorboard-data-server, rsa, PyYAML, pyasn1-modules, protobuf, PrettyTable, pillow, pbr, oauthlib, numpy, multidict, markdown, Mako, kiwisolver, joblib, grpcio, greenlet, fsspec, frozenlist, fonttools, cycler, colorlog, cmd2, charset-normalizer, certifi, cachetools, autopage, async-timeout, absl-py, yarl, torch, stevedore, sqlalchemy, scipy, requests, patsy, pandas, importlib-metadata, google-auth, fire, contourpy, cmaes, aiosignal, torchmetrics, statsmodels, scikit-learn, requests-oauthlib, matplotlib, lightning-utilities, cliff, alembic, aiohttp, optuna, google-auth-oauthlib, tensorboard, pytorch-lightning, pytorch_forecasting\n",
      "  Running setup.py install for pyperclip: started\n",
      "  Running setup.py install for pyperclip: finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp310-cp310-win_amd64.whl (167.3 MB)\n",
      "     ------------------------------------ 167.3/167.3 MB 302.6 kB/s eta 0:00:00\n",
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-1.8.1-py3-none-any.whl (798 kB)\n",
      "Collecting pytorch_forecasting\n",
      "  Using cached pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting lightning-utilities==0.3.*\n",
      "  Using cached lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\python310\\lib\\site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Using cached torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
      "Collecting PyYAML>=5.4\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Using cached fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting fire\n",
      "  Using cached fire-0.4.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.6.2-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "Collecting scipy<2.0,>=1.8\n",
      "  Using cached scipy-1.9.3-cp310-cp310-win_amd64.whl (40.1 MB)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.13.5-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "     ---------------------------------------- 9.1/9.1 MB 760.1 kB/s eta 0:00:00\n",
      "Collecting optuna<3.0.0,>=2.3.0\n",
      "  Using cached optuna-2.10.1-py3-none-any.whl (308 kB)\n",
      "Collecting scikit-learn<1.2,>=0.24\n",
      "  Using cached scikit_learn-1.1.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "Collecting pandas<2.0.0,>=1.3.0\n",
      "  Using cached pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.8.3-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting cliff\n",
      "  Using cached cliff-4.0.0-py3-none-any.whl (80 kB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Using cached cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Using cached SQLAlchemy-1.4.43-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting protobuf<4,>=3.9.2\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.50.0-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python310\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (58.1.0)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.4)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.6-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp310-cp310-win_amd64.whl (27 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.1-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-2.0.1-cp310-cp310-win_amd64.whl (190 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning) (2.1.1)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.3-py3-none-any.whl (78 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Using cached autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Using cached prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Using cached cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Using cached stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting termcolor\n",
      "  Using cached termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Using cached pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\python310\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.5)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Using cached pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pytz, pyreadline3, pyperclip, pyasn1, zipp, wheel, werkzeug, urllib3, typing-extensions, tqdm, threadpoolctl, termcolor, tensorboard-data-server, rsa, PyYAML, pyasn1-modules, protobuf, PrettyTable, pillow, pbr, oauthlib, numpy, multidict, markdown, Mako, kiwisolver, joblib, grpcio, greenlet, fsspec, frozenlist, fonttools, cycler, colorlog, cmd2, charset-normalizer, certifi, cachetools, autopage, async-timeout, absl-py, yarl, torch, stevedore, sqlalchemy, scipy, requests, patsy, pandas, importlib-metadata, google-auth, fire, contourpy, cmaes, aiosignal, torchmetrics, statsmodels, scikit-learn, requests-oauthlib, matplotlib, lightning-utilities, cliff, alembic, aiohttp, optuna, google-auth-oauthlib, tensorboard, pytorch-lightning, pytorch_forecasting\n",
      "  Running setup.py install for pyperclip: started\n",
      "  Running setup.py install for pyperclip: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "  DEPRECATION: pyperclip is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python310\\\\Scripts\\\\wheel.exe' -> 'C:\\\\Python310\\\\Scripts\\\\wheel.exe.deleteme'\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp310-cp310-win_amd64.whl (167.3 MB)\n",
      "     -------------------------------------- 167.3/167.3 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-1.8.1-py3-none-any.whl (798 kB)\n",
      "Collecting pytorch_forecasting\n",
      "  Using cached pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting PyYAML>=5.4\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Using cached fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Using cached torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
      "Collecting lightning-utilities==0.3.*\n",
      "  Using cached lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\python310\\lib\\site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting fire\n",
      "  Using cached fire-0.4.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scipy<2.0,>=1.8\n",
      "  Using cached scipy-1.9.3-cp310-cp310-win_amd64.whl (40.1 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.6.2-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "Collecting statsmodels\n",
      "  Using cached statsmodels-0.13.5-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "Collecting pandas<2.0.0,>=1.3.0\n",
      "  Using cached pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "Collecting scikit-learn<1.2,>=0.24\n",
      "  Using cached scikit_learn-1.1.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "Collecting optuna<3.0.0,>=2.3.0\n",
      "  Using cached optuna-2.10.1-py3-none-any.whl (308 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.8.3-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Using cached cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "Collecting cliff\n",
      "  Using cached cliff-4.0.0-py3-none-any.whl (80 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Using cached SQLAlchemy-1.4.43-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting protobuf<4,>=3.9.2\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python310\\\\Scripts\\\\wheel.exe' -> 'C:\\\\Python310\\\\Scripts\\\\wheel.exe.deleteme'\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python310\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (58.1.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.50.0-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.4)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.6-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp310-cp310-win_amd64.whl (27 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.1-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-2.0.1-cp310-cp310-win_amd64.whl (190 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning) (2.1.1)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.3-py3-none-any.whl (78 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Using cached autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Using cached prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Using cached cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Using cached stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
      "Collecting termcolor\n",
      "  Using cached termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Using cached pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\python310\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.5)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Using cached pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: fire, pyperclip\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115961 sha256=03bd165b87d43ff3e7326db37202079cc752a75b469244f1b42f0c21f1cfd1db\n",
      "  Stored in directory: c:\\users\\benja\\appdata\\local\\pip\\cache\\wheels\\a5\\e5\\b1\\36f99d92494185177f07f79579ae168cb034574e98e9b16ae5\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11149 sha256=0b2e1a97ba01be2a90f744fa989d665f1a2c9eb1b9971f0a3e03d135d437d702\n",
      "  Stored in directory: c:\\users\\benja\\appdata\\local\\pip\\cache\\wheels\\3c\\77\\81\\aaa2802e9b0553585f2789c6f2756b50a09a01d2848423bb15\n",
      "Successfully built fire pyperclip\n",
      "Installing collected packages: tensorboard-plugin-wit, pytz, pyreadline3, pyperclip, pyasn1, zipp, wheel, werkzeug, urllib3, typing-extensions, tqdm, threadpoolctl, termcolor, tensorboard-data-server, rsa, PyYAML, pyasn1-modules, protobuf, PrettyTable, pillow, pbr, oauthlib, numpy, multidict, markdown, Mako, kiwisolver, joblib, grpcio, greenlet, fsspec, frozenlist, fonttools, cycler, colorlog, cmd2, charset-normalizer, certifi, cachetools, autopage, async-timeout, absl-py, yarl, torch, stevedore, sqlalchemy, scipy, requests, patsy, pandas, importlib-metadata, google-auth, fire, contourpy, cmaes, aiosignal, torchmetrics, statsmodels, scikit-learn, requests-oauthlib, matplotlib, lightning-utilities, cliff, alembic, aiohttp, optuna, google-auth-oauthlib, tensorboard, pytorch-lightning, pytorch_forecasting\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch pytorch-lightning pytorch_forecasting numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1e824d",
   "metadata": {},
   "source": [
    "import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8fe358c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14644/4005481756.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_forecasting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimeSeriesDataSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer\n",
    "from pytorch_forecasting.models.baseline import Baseline\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics.quantile import QuantileLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3dde68-bcb6-4117-a419-37b3de866354",
   "metadata": {},
   "source": [
    "Steps to execute:\n",
    "1. Create a pandas dataframe with our time-series data.\n",
    "2. Wrap our dataframe into a TimeSeriesDataset instance.\n",
    "3. Pass our TimeSeriesDataset instance to TemporalFusionTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e96178-569a-4fdc-b6b6-3bb3230da9f1",
   "metadata": {},
   "source": [
    "Minimal dataset\n",
    "First create a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6146a372-35c0-4fed-b63f-4f47b40642b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_idx</th>\n",
       "      <th>target</th>\n",
       "      <th>group</th>\n",
       "      <th>holidays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Black Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Black Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>Black Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_idx  target  group      holidays\n",
       "0          0       0      0             X\n",
       "1          1       1      0  Black Friday\n",
       "2          2       2      0             X\n",
       "3          3       3      0     Christmas\n",
       "4          4       4      0             X\n",
       "5          5       5      0             X\n",
       "6          0      20      1             X\n",
       "7          1      21      1  Black Friday\n",
       "8          2      22      1             X\n",
       "9          3      23      1     Christmas\n",
       "10         4      24      1             X\n",
       "11         5      25      1             X\n",
       "12         0      40      2             X\n",
       "13         1      41      2  Black Friday\n",
       "14         2      42      2             X\n",
       "15         3      43      2     Christmas\n",
       "16         4      44      2             X\n",
       "17         5      45      2             X"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.DataFrame(\n",
    "    dict(\n",
    "        time_idx=np.tile(np.arange(6), 3),\n",
    "        target=np.array([0,1,2,3,4,5,20,21,22,23,24,25,40,41,42,43,44,45]),\n",
    "        group=np.repeat(np.arange(3), 6),\n",
    "        holidays = np.tile(['X','Black Friday', 'X','Christmas','X', 'X'],3),\n",
    "    )\n",
    ")\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6482c5-36f9-487f-8222-d79bdd4f84fb",
   "metadata": {},
   "source": [
    "Then convert the dataframe into a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88b02e4-4de0-40a9-ace9-b4d669878c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TimeSeriesDataSet(\n",
    "    sample_data,\n",
    "    group_ids=[\"group\"],\n",
    "    target=\"target\",\n",
    "    time_idx=\"time_idx\",\n",
    "    max_encoder_length=2,\n",
    "    max_prediction_length=3,\n",
    "    time_varying_unknown_reals=[\"target\"],\n",
    "    static_categoricals=[\"holidays\"],\n",
    "    target_normalizer=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419c263-6785-460d-bb03-74d293471cec",
   "metadata": {},
   "source": [
    "This is how the dataset will be passed to the TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ba471c-eedd-4a39-a6f8-13765b493a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21., 22.]])\n",
      "tensor([[1]])\n",
      "\n",
      "\n",
      "tensor([[23., 24., 25.]])\n"
     ]
    }
   ],
   "source": [
    "# pass the dataset to a dataloader\n",
    "dataloader = dataset.to_dataloader(batch_size=1)\n",
    "\n",
    "#load the first batch\n",
    "x, y = next(iter(dataloader))\n",
    "print(x['encoder_target'])\n",
    "print(x['groups'])\n",
    "print('\\n')\n",
    "print(x['decoder_target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3826715d-d983-4a21-ae54-68b9df540952",
   "metadata": {},
   "source": [
    "# See it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ffdb29-ecc6-46a5-8a5e-f16bec407915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-12 07:41:13--  https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252, 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 261335609 (249M) [application/x-httpd-php]\n",
      "Saving to: ‘LD2011_2014.txt.zip.1’\n",
      "\n",
      "LD2011_2014.txt.zip  11%[=>                  ]  27.52M  5.54MB/s    eta 51s    ^C\n",
      "Archive:  LD2011_2014.txt.zip\n",
      "replace LD2011_2014.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip\n",
    "!unzip LD2011_2014.txt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6698f0c1-6782-4243-8f25-85c6e77ba8b0",
   "metadata": {},
   "source": [
    "Put the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fadbda88-9092-49f6-96f4-61d876aebef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>...</th>\n",
       "      <th>MT_361</th>\n",
       "      <th>MT_362</th>\n",
       "      <th>MT_363</th>\n",
       "      <th>MT_364</th>\n",
       "      <th>MT_365</th>\n",
       "      <th>MT_366</th>\n",
       "      <th>MT_367</th>\n",
       "      <th>MT_368</th>\n",
       "      <th>MT_369</th>\n",
       "      <th>MT_370</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  MT_007  \\\n",
       "2011-01-01 00:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-01 00:30:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-01 00:45:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-01 01:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "                     MT_008  MT_009  MT_010  ...  MT_361  MT_362  MT_363  \\\n",
       "2011-01-01 00:15:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-01 00:30:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-01 00:45:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-01 01:00:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-01 01:15:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "\n",
       "                     MT_364  MT_365  MT_366  MT_367  MT_368  MT_369  MT_370  \n",
       "2011-01-01 00:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-01 00:30:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-01 00:45:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-01 01:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('LD2011_2014.txt', index_col=0, sep=';', decimal=',')\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.sort_index(inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e41d10-f929-483d-8ce2-975f28508eaa",
   "metadata": {},
   "source": [
    "Aggregate data by hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31cfbdc-47ce-4359-b5bd-58dda185b848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>25.248933</td>\n",
       "      <td>186.483740</td>\n",
       "      <td>92.073171</td>\n",
       "      <td>340.773810</td>\n",
       "      <td>315.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>22.759602</td>\n",
       "      <td>162.093496</td>\n",
       "      <td>86.280488</td>\n",
       "      <td>319.940476</td>\n",
       "      <td>269.360269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>22.048364</td>\n",
       "      <td>161.077236</td>\n",
       "      <td>86.890244</td>\n",
       "      <td>314.732143</td>\n",
       "      <td>251.683502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>21.337127</td>\n",
       "      <td>161.585366</td>\n",
       "      <td>83.841463</td>\n",
       "      <td>308.035714</td>\n",
       "      <td>250.841751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>19.914651</td>\n",
       "      <td>178.861789</td>\n",
       "      <td>84.146341</td>\n",
       "      <td>279.761905</td>\n",
       "      <td>249.158249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35065 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MT_002      MT_004     MT_005      MT_006      MT_008\n",
       "2011-01-01 00:00:00        NaN         NaN        NaN         NaN         NaN\n",
       "2011-01-01 01:00:00        NaN         NaN        NaN         NaN         NaN\n",
       "2011-01-01 02:00:00        NaN         NaN        NaN         NaN         NaN\n",
       "2011-01-01 03:00:00        NaN         NaN        NaN         NaN         NaN\n",
       "2011-01-01 04:00:00        NaN         NaN        NaN         NaN         NaN\n",
       "...                        ...         ...        ...         ...         ...\n",
       "2014-12-31 20:00:00  25.248933  186.483740  92.073171  340.773810  315.656566\n",
       "2014-12-31 21:00:00  22.759602  162.093496  86.280488  319.940476  269.360269\n",
       "2014-12-31 22:00:00  22.048364  161.077236  86.890244  314.732143  251.683502\n",
       "2014-12-31 23:00:00  21.337127  161.585366  83.841463  308.035714  250.841751\n",
       "2015-01-01 00:00:00  19.914651  178.861789  84.146341  279.761905  249.158249\n",
       "\n",
       "[35065 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.resample('1h').mean().replace(0., np.nan)\n",
    "earliest_time = data.index.min()\n",
    "df=data[['MT_002', 'MT_004', 'MT_005', 'MT_006', 'MT_008' ]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263b16f5-04dd-43a3-a021-ccf98c3308b1",
   "metadata": {},
   "source": [
    "Reformat data frame to match expected input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9569d5ab-14cd-42a0-bdfb-6ab9d4bb3354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_usage</th>\n",
       "      <th>hours_from_start</th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>date</th>\n",
       "      <th>consumer_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17544</th>\n",
       "      <td>24.004267</td>\n",
       "      <td>26304</td>\n",
       "      <td>1096</td>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>MT_002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17545</th>\n",
       "      <td>23.293030</td>\n",
       "      <td>26305</td>\n",
       "      <td>1096</td>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>MT_002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17546</th>\n",
       "      <td>24.537696</td>\n",
       "      <td>26306</td>\n",
       "      <td>1096</td>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>MT_002</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17547</th>\n",
       "      <td>21.870555</td>\n",
       "      <td>26307</td>\n",
       "      <td>1096</td>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>MT_002</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17548</th>\n",
       "      <td>22.226174</td>\n",
       "      <td>26308</td>\n",
       "      <td>1096</td>\n",
       "      <td>2014-01-01 04:00:00</td>\n",
       "      <td>MT_002</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128759</th>\n",
       "      <td>249.158249</td>\n",
       "      <td>32299</td>\n",
       "      <td>1345</td>\n",
       "      <td>2014-09-07 19:00:00</td>\n",
       "      <td>MT_008</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128760</th>\n",
       "      <td>303.030303</td>\n",
       "      <td>32300</td>\n",
       "      <td>1345</td>\n",
       "      <td>2014-09-07 20:00:00</td>\n",
       "      <td>MT_008</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128761</th>\n",
       "      <td>306.397306</td>\n",
       "      <td>32301</td>\n",
       "      <td>1345</td>\n",
       "      <td>2014-09-07 21:00:00</td>\n",
       "      <td>MT_008</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128762</th>\n",
       "      <td>279.461279</td>\n",
       "      <td>32302</td>\n",
       "      <td>1345</td>\n",
       "      <td>2014-09-07 22:00:00</td>\n",
       "      <td>MT_008</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128763</th>\n",
       "      <td>250.841751</td>\n",
       "      <td>32303</td>\n",
       "      <td>1345</td>\n",
       "      <td>2014-09-07 23:00:00</td>\n",
       "      <td>MT_008</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        power_usage  hours_from_start  days_from_start                date  \\\n",
       "17544     24.004267             26304             1096 2014-01-01 00:00:00   \n",
       "17545     23.293030             26305             1096 2014-01-01 01:00:00   \n",
       "17546     24.537696             26306             1096 2014-01-01 02:00:00   \n",
       "17547     21.870555             26307             1096 2014-01-01 03:00:00   \n",
       "17548     22.226174             26308             1096 2014-01-01 04:00:00   \n",
       "...             ...               ...              ...                 ...   \n",
       "128759   249.158249             32299             1345 2014-09-07 19:00:00   \n",
       "128760   303.030303             32300             1345 2014-09-07 20:00:00   \n",
       "128761   306.397306             32301             1345 2014-09-07 21:00:00   \n",
       "128762   279.461279             32302             1345 2014-09-07 22:00:00   \n",
       "128763   250.841751             32303             1345 2014-09-07 23:00:00   \n",
       "\n",
       "       consumer_id  hour  day  day_of_week  month  \n",
       "17544       MT_002     0    1            2      1  \n",
       "17545       MT_002     1    1            2      1  \n",
       "17546       MT_002     2    1            2      1  \n",
       "17547       MT_002     3    1            2      1  \n",
       "17548       MT_002     4    1            2      1  \n",
       "...            ...   ...  ...          ...    ...  \n",
       "128759      MT_008    19    7            6      9  \n",
       "128760      MT_008    20    7            6      9  \n",
       "128761      MT_008    21    7            6      9  \n",
       "128762      MT_008    22    7            6      9  \n",
       "128763      MT_008    23    7            6      9  \n",
       "\n",
       "[30000 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "\n",
    "for label in df:\n",
    "\n",
    "    ts = df[label]\n",
    "\n",
    "    start_date = min(ts.fillna(method='ffill').dropna().index)\n",
    "    end_date = max(ts.fillna(method='bfill').dropna().index)\n",
    "\n",
    "    active_range = (ts.index >= start_date) & (ts.index <= end_date)\n",
    "    ts = ts[active_range].fillna(0.)\n",
    "\n",
    "    tmp = pd.DataFrame({'power_usage': ts})\n",
    "    date = tmp.index\n",
    "\n",
    "    tmp['hours_from_start'] = (date - earliest_time).seconds / 60 / 60 + (date - earliest_time).days * 24\n",
    "    tmp['hours_from_start'] = tmp['hours_from_start'].astype('int')\n",
    "  \n",
    "    tmp['days_from_start'] = (date - earliest_time).days\n",
    "    tmp['date'] = date\n",
    "    tmp['consumer_id'] = label\n",
    "    tmp['hour'] = date.hour\n",
    "    tmp['day'] = date.day\n",
    "    tmp['day_of_week'] = date.dayofweek\n",
    "    tmp['month'] = date.month\n",
    "\n",
    "    #stack all time series vertically\n",
    "    df_list.append(tmp)\n",
    "\n",
    "time_df = pd.concat(df_list).reset_index(drop=True)\n",
    "\n",
    "# match results in the original paper\n",
    "time_df = time_df[(time_df['days_from_start'] >= 1096)\n",
    "                & (time_df['days_from_start'] < 1346)].copy()\n",
    "\n",
    "time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157da4f-edac-4c87-82ab-2e7bbcb0c9ae",
   "metadata": {},
   "source": [
    "Take a closer look into the data, average consumption by consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a813bdc3-11f3-4ceb-8508-b8603bef0c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_usage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumer_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MT_002</th>\n",
       "      <td>27.472588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT_004</th>\n",
       "      <td>120.573001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT_005</th>\n",
       "      <td>50.958384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT_006</th>\n",
       "      <td>183.387773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT_008</th>\n",
       "      <td>248.884259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             power_usage\n",
       "consumer_id             \n",
       "MT_002         27.472588\n",
       "MT_004        120.573001\n",
       "MT_005         50.958384\n",
       "MT_006        183.387773\n",
       "MT_008        248.884259"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df[['consumer_id','power_usage']].groupby('consumer_id').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e5e3f-8142-4982-8695-93b4920f37e9",
   "metadata": {},
   "source": [
    "Create data loaders for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8aca77f-a89a-4670-abf4-0c4c30bd0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 24\n",
    "max_encoder_length = 7*24\n",
    "training_cutoff = time_df[\"hours_from_start\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    time_df[lambda x: x.hours_from_start <= training_cutoff],\n",
    "    time_idx=\"hours_from_start\",\n",
    "    target=\"power_usage\",\n",
    "    group_ids=[\"consumer_id\"],\n",
    "    min_encoder_length=max_encoder_length // 2, \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"consumer_id\"],\n",
    "    time_varying_known_reals=[\"hours_from_start\",\"day\",\"day_of_week\", \"month\", 'hour'],\n",
    "    time_varying_unknown_reals=['power_usage'],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"consumer_id\"], transformation=\"softplus\"\n",
    "    ),  # we normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, time_df, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for  our model\n",
    "batch_size = 64 \n",
    "# if you have a strong GPU, feel free to increase the number of workers  \n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=4)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5933cf-9105-441e-b079-95d5abaf4cf5",
   "metadata": {},
   "source": [
    "Define a baseline prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2802b918-ab9b-4159-b284-c4e6a840e35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.139617919921875"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8584365-ff37-4eb4-99ce-27b4f40691c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 20    \n",
      "3  | prescalers                         | ModuleDict                      | 3.2 K \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 313 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 734 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 628 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 103 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 103 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 103 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 103 K \n",
      "11 | lstm_encoder                       | LSTM                            | 206 K \n",
      "12 | lstm_decoder                       | LSTM                            | 206 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 51.5 K\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 320   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 128 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 64.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 51.8 K\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 103 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 51.8 K\n",
      "20 | output_layer                       | Linear                          | 1.1 K \n",
      "----------------------------------------------------------------------------------------\n",
      "3.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 M     Total params\n",
      "11.818    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9432a4fdb5c64926a9fa9ba103313840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=True, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  \n",
    "logger = TensorBoardLogger(\"lightning_logs\")  \n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=45,\n",
    "    # accelerator='gpu', # if supported by your hardware \n",
    "    devices=1,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.001,\n",
    "    hidden_size=160,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=160,\n",
    "    output_size=7,  # there are 7 quantiles by default: [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10, \n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71d0a3ac-486d-4c44-908b-ac2e9b4771b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning_logs/lightning_logs/version_3/checkpoints/epoch=0-step=468.ckpt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jovyan/work/lightning_logs/lightning_logs/version_3/checkpoints/epoch=0-step=468.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcheckpoint_callback\u001b[38;5;241m.\u001b[39mbest_model_path\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_model_path)\n\u001b[0;32m----> 3\u001b[0m best_tft \u001b[38;5;241m=\u001b[39m \u001b[43mTemporalFusionTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     65\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:  \u001b[38;5;66;03m# type: ignore[valid-type]\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:158\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m cast(_MAP_LOCATION_TYPE, \u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m--> 158\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hparams_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(hparams_file)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning_lite/utilities/cloud_io.py:47\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[1;32m     44\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type] # upstream annotation is not correct\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fsspec/spec.py:1094\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1093\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1094\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fsspec/implementations/local.py:175\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fsspec/implementations/local.py:273\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 273\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fsspec/implementations/local.py:278\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m--> 278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[1;32m    280\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/work/lightning_logs/lightning_logs/version_3/checkpoints/epoch=0-step=468.ckpt'"
     ]
    }
   ],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(best_model_path)\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95b0a366-952c-45c2-92f8-b54154cb2bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
       "                   [--host ADDR] [--bind_all] [--port PORT]\n",
       "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
       "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
       "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
       "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
       "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
       "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
       "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
       "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
       "                   [--reload_multifile BOOL]\n",
       "                   [--reload_multifile_inactive_secs SECONDS]\n",
       "                   [--generic_data TYPE]\n",
       "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
       "                   [--detect_file_replacement BOOL]\n",
       "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
       "                   [--whatif-data-dir PATH]\n",
       "                   {serve,dev} ...\n",
       "tensorboard: error: argument {serve,dev}: invalid choice: '-' (choose from 'serve', 'dev')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard - logdir lightning_logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37f6d7af-9c92-483d-8e34-23e59c84a7a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_tft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m actuals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([y[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(val_dataloader)])\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mbest_tft\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(val_dataloader)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#average p50 loss overall\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m((actuals \u001b[38;5;241m-\u001b[39m predictions)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_tft' is not defined"
     ]
    }
   ],
   "source": [
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "\n",
    "#average p50 loss overall\n",
    "print((actuals - predictions).abs().mean().item())\n",
    "#average p50 loss per time series\n",
    "print((actuals - predictions).abs().mean(axis=1))\n",
    "\n",
    "# ➢6.686748027801514\n",
    "# ➢tensor([ 1.5708,  8.7656,  1.9709,  8.1660, 12.9604])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669bfd05-82c6-412c-96e6-75ea0a225b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at what the raw_predictions variable contains\n",
    "\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "print(raw_predictions._fields)\n",
    "# ('prediction', \n",
    "# 'encoder_attention', \n",
    "# 'decoder_attention', \n",
    "# 'static_variables', \n",
    "# 'encoder_variables', \n",
    "# 'decoder_variables', \n",
    "# 'decoder_lengths', \n",
    "# 'encoder_lengths')\n",
    "\n",
    "print('\\n')\n",
    "print(raw_predictions['prediction'].shape)\n",
    "#torch.Size([5, 24, 7])\n",
    "\n",
    "# We get predictions of 5 time-series for 24 days.\n",
    "# For each day we get 7 predictions - these are the 7 quantiles:\n",
    "#[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]\n",
    "# We are mostly interested in the 4th quantile which represents, let's say, the 'median loss'\n",
    "# fyi, although docs use the term quantiles, the most accurate term are percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a186db-0a72-4256-9b60-a87a27ea9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx in range(5):  # plot all 5 consumers\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090ea9d-fc97-4b4d-bc3b-49c358c7f6ee",
   "metadata": {},
   "source": [
    "Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05c7d2-f276-467c-9248-7fd420ad8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "interpretation = best_tft.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5eaef-d2a5-46bc-80a4-9ee4a39416d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
